# 🧠 Safe Research AI
A student-built project to make AI safer and more useful for research and study environments.

## 🚀 Mission
Most AI assistants are powerful but not optimized for research safety or academic integrity.  
Safe Research AI is designed to:
- **Help students and researchers** organize study materials, summarize sources, and generate insights responsibly.
- **Provide built-in safety layers** to prevent biased, unethical, or unsafe outputs.
- **Encourage transparent, reproducible research** by logging AI queries and their sources.

## 🧩 Core Features
- **Safety Layer (`safety.py`)** — filters and audits AI outputs for compliance with research standards.
- **Retrieval Module (`retrieval.py`)** — fetches academic or local documents for context-aware responses.
- **Embeddings (`embeddings.py`)** — vectorizes research data for semantic search and clustering.
- **Audit Log (`audit_log.py`)** — keeps track of AI activity for accountability and reproducibility.
- **Main Application (`main.py`)** — central API for interaction, processing, and response generation.

## ⚙️ Tech Stack
- Python 3.11+
- LangChain / OpenAI API
- FastAPI (for local or cloud deployment)
- FAISS or Chroma for vector storage
- GitHub Actions for automated safety testing (planned)

## 🧪 Roadmap
- Integrate with Google Scholar / Semantic Scholar API
- Add local document upload and semantic search
- Build user dashboard for research tracking
- Deploy demo app on Hugging Face Spaces
- Publish whitepaper on ethical AI in student research

## 💡 Inspiration
*"AI should accelerate human discovery — not replace it."*  
This project started as a personal research initiative to explore how AI can assist students and labs safely.  
Created and maintained by **Ray Kim**, high-school researcher and aspiring computer scientist.

## 📫 Contact
If you’re interested in collaborating or testing Safe Research AI:  
- GitHub: [@rayray0613](https://github.com/rayray0613)
